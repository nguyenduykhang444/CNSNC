import os
import dotenv
import google.generativeai as genai
import streamlit as st
import re            
import random        


# --- C·∫§U H√åNH GEMINI ---
dotenv.load_dotenv()
api_key = os.getenv("GOOGLE_API_KEY")
if not api_key:
    try:
        api_key = st.secrets["GOOGLE_API_KEY"]
    except KeyError:
        st.error("‚ùå Kh√¥ng t√¨m th·∫•y GOOGLE_API_KEY. Vui l√≤ng thi·∫øt l·∫≠p trong .env ho·∫∑c Streamlit Secrets.")
        st.stop()
try:
    genai.configure(api_key=api_key)
    model = genai.GenerativeModel("gemini-2.5-flash")
except Exception as e:
    st.error(f"L·ªói khi c·∫•u h√¨nh Gemini: {e}")
    st.stop()

# --- H√ÄM LOAD D·ªÆ LI·ªÜU ---
@st.cache_data(ttl=600)
def load_data():
    """T·∫£i v√† n·ªëi t·∫•t c·∫£ d·ªØ li·ªáu t·ª´ c√°c file .txt trong th∆∞ m·ª•c 'data'."""
    data_dir = "data"
    data = ""
    if not os.path.exists(data_dir):
        st.warning(f"‚ö†Ô∏è Th∆∞ m·ª•c '{data_dir}' ch∆∞a t·ªìn t·∫°i. Chatbot s·∫Ω ch·∫°y ·ªü ch·∫ø ƒë·ªô th√¥ng th∆∞·ªùng.")
        return None
    files = [f for f in os.listdir(data_dir) if f.endswith(".txt")]
    if not files:
        st.warning("‚ö†Ô∏è Ch∆∞a c√≥ file .txt trong th∆∞ m·ª•c 'data/'. Chatbot s·∫Ω ch·∫°y ·ªü ch·∫ø ƒë·ªô th√¥ng th∆∞·ªùng.")
        return None
    for file in files:
        try:
            with open(os.path.join(data_dir, file), "r", encoding="utf-8") as f:
                data += f.read() + "\n\n"
        except Exception as e:
            st.error(f"L·ªói khi ƒë·ªçc file {file}: {e}") 
    return data.strip() if data else None

# --- ƒê·∫∂T QUY T·∫ÆC CHO MODEL ---
def initialize_chat(data):
    """Kh·ªüi t·∫°o phi√™n chat m·ªõi v·ªõi b·ªëi c·∫£nh (system prompt) n·∫øu c√≥."""
    default_greeting = "Ch√†o b·∫°n! Hi·ªán t·∫°i t√¥i ch∆∞a c√≥ d·ªØ li·ªáu v·ªÅ nu√¥i t√¥m. T√¥i c√≥ th·ªÉ gi√∫p g√¨ cho b·∫°n (·ªü ch·∫ø ƒë·ªô th√¥ng th∆∞·ªùng)?"   
    if data:
        SYSTEM_PROMPT = f"""
        B·∫°n l√† m·ªôt tr·ª£ l√Ω AI chuy√™n gia v·ªÅ quy tr√¨nh nu√¥i t√¥m th·∫ª ch√¢n tr·∫Øng.
        Nhi·ªám v·ª• c·ªßa b·∫°n l√† tr·∫£ l·ªùi c√°c c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng CH·ªà D·ª∞A TR√äN N·ªòI DUNG SAU ƒê√ÇY:

        --- N·ªòI DUNG THAM KH·∫¢O ---
        {data}
        --- K·∫æT TH√öC N·ªòI DUNG ---

        QUY T·∫ÆC TUY·ªÜT ƒê·ªêI:
        1. Ch·ªâ tr·∫£ l·ªùi d·ª±a v√†o "N·ªòI DUNG THAM KH·∫¢O"ƒë√£ cung c·∫•p.
        2. N·∫øu c√¢u h·ªèi kh√¥ng th·ªÉ tr·∫£ l·ªùi b·∫±ng n·ªôi dung tr√™n, h√£y n√≥i: "Xin l·ªói, t√¥i kh√¥ng t√¨m th·∫•y th√¥ng tin n√†y trong t√†i li·ªáu."
        3. Kh√¥ng t·ª± √Ω b·ªãa ƒë·∫∑t th√¥ng tin ho·∫∑c l·∫•y ki·∫øn th·ª©c b√™n ngo√†i.
        4. Tr·∫£ l·ªùi m·ªôt c√°ch ng·∫Øn g·ªçn, ch√≠nh x√°c v√† chuy√™n nghi·ªáp.
        5. Khi m√¥ t·∫£ v·ªÅ m·ªôt b·ªánh m√† c√≥ th·∫ª [IMAGE_PATH_DIR: ...], B·∫†N PH·∫¢I GI·ªÆ NGUY√äN th·∫ª ƒë√≥ trong c√¢u tr·∫£ l·ªùi.
        """
        try:
            chat = model.start_chat(history=[
                {"role": "user", "parts": [SYSTEM_PROMPT]},
                {"role": "model", "parts": ["Xin ch√†o! T√¥i l√† tr·ª£ l√Ω chuy√™n v·ªÅ nu√¥i t√¥m. B·∫°n c·∫ßn h·ªó tr·ª£ g√¨ h√¥m nay?"]} # S·ª≠a l·ªùi ch√†o
            ])
            st.session_state.context_loaded = True
            return chat
        except Exception as e:
            st.error(f"L·ªói khi b·∫Øt ƒë·∫ßu chat v·ªõi model: {e}")
            st.stop()
    st.session_state.context_loaded = False
    return model.start_chat(history=[
        {"role": "user", "parts": ["Xin ch√†o"]},
        {"role": "model", "parts": [default_greeting]}
    ])

# --- H√ÄM X·ª¨ L√ù VƒÇN B·∫¢N V√Ä CH·ªåN ·∫¢NH (D√ôNG CACHE) ---
@st.cache_data(ttl=3600)
def get_processed_display_parts(text_content):
    image_tag_pattern = r"\[IMAGE_PATH_DIR:\s*(.*?)\s*\]"
    dir_paths = re.findall(image_tag_pattern, text_content)
    clean_text = re.sub(image_tag_pattern, "", text_content).strip()
    chosen_image_path = None
    if dir_paths:
        dir_path = dir_paths[0]
        if os.path.isdir(dir_path):
            try:
                image_files = [
                    f for f in os.listdir(dir_path) 
                    if f.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp'))
                ]             
                if image_files:
                    random_image = random.choice(image_files)
                    chosen_image_path = os.path.join(dir_path, random_image)
                else:
                    st.warning(f"‚ö†Ô∏è Th∆∞ m·ª•c '{dir_path}' ƒë∆∞·ª£c t√¨m th·∫•y nh∆∞ng kh√¥ng ch·ª©a file ·∫£nh n√†o.")
            except Exception as e:
                st.error(f"L·ªói khi truy c·∫≠p ho·∫∑c ƒë·ªçc ·∫£nh t·ª´ th∆∞ m·ª•c '{dir_path}': {e}")
        else:
            st.warning(f"‚ö†Ô∏è Chatbot ƒë√£ tr·∫£ v·ªÅ ƒë∆∞·ªùng d·∫´n ·∫£nh, nh∆∞ng th∆∞ m·ª•c '{dir_path}' kh√¥ng t·ªìn t·∫°i tr√™n m√°y ch·ªß.")  
    return clean_text, chosen_image_path
        
# --- GIAO DI·ªÜN CH√çNH---
st.set_page_config(page_title="Chatbot Nu√¥i T√¥m", page_icon="ü¶ê", layout="wide")
st.title("ü¶ê Chatbot H·ªèi-ƒê√°p v·ªÅ Quy Tr√¨nh Nu√¥i T√¥m")

# --- THANH B√äN (SIDEBAR) ---
with st.sidebar:
    st.header("Thi·∫øt l·∫≠p")
    if st.button("üóëÔ∏è X√≥a l·ªãch s·ª≠ & T·∫£i l·∫°i ng·ªØ c·∫£nh", use_container_width=True):
        if "chat" in st.session_state:
            del st.session_state.chat
        if "display_messages" in st.session_state:
            del st.session_state.display_messages     
        st.cache_data.clear() 
        st.rerun()
# --- T·∫¢I D·ªÆ LI·ªÜU V√Ä KH·ªûI T·∫†O CHAT ---
if "chat" not in st.session_state:
    loaded_shrimp_data = load_data()
    st.session_state.chat = initialize_chat(loaded_shrimp_data)
    st.session_state.display_messages = []
    for turn in st.session_state.chat.history:
        if "N·ªòI DUNG THAM KH·∫¢O" in turn.parts[0].text:
            continue
        role = "assistant" if turn.role == "model" else "user"
        if role == "assistant":
            clean_text, image_path = get_processed_display_parts(turn.parts[0].text)
            st.session_state.display_messages.append(
                {"role": role, "text": clean_text, "image": image_path}
            )
        else:
            st.session_state.display_messages.append(
                {"role": role, "text": turn.parts[0].text, "image": None}
            )
if st.session_state.context_loaded:
    st.status("ƒê√£ t·∫£i b·ªëi c·∫£nh t·ª´ th∆∞ m·ª•c `data/`", state="complete")
else:
    st.status("Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu. Chatbot ƒëang ch·∫°y ·ªü ch·∫ø ƒë·ªô chung.", state="error")

# --- KHUNG HI·ªÇN TH·ªä L·ªäCH S·ª¨ CHAT ---
for msg in st.session_state.display_messages:
    with st.chat_message(msg["role"]):
        if msg["text"]:
            st.markdown(msg["text"])
        if msg["image"]:
            try:
                st.image(msg["image"], width=300)
            except Exception as e:
                st.error(f"L·ªói khi hi·ªÉn th·ªã ·∫£nh {msg['image']}: {e}")

# --- KHUNG NH·∫¨P LI·ªÜU ---
if prompt := st.chat_input("H·ªèi v·ªÅ quy tr√¨nh nu√¥i t√¥m..."):
    with st.chat_message("user"):
        st.markdown(prompt)
    st.session_state.display_messages.append(
        {"role": "user", "text": prompt, "image": None}
    )
    try:
        chat = st.session_state.chat
        with st.spinner("Bot ƒëang suy nghƒ©..."):
            response = chat.send_message(prompt)
        last_bot_message_text = chat.history[-1].parts[0].text
        clean_text, image_path = get_processed_display_parts(last_bot_message_text)
        st.session_state.display_messages.append(
            {"role": "assistant", "text": clean_text, "image": image_path}
        )
        st.rerun() 
            
    except Exception as e:
        st.error(f"‚ùå L·ªói khi g·ª≠i tin nh·∫Øn: {e}")